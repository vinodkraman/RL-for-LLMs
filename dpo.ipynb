{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUPxc9c7CVNrRbZBGU3038",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinodkraman/RL4LLMs/blob/main/dpo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGB9lqu9nG74"
      },
      "outputs": [],
      "source": [
        "#install packages\n",
        "!pip install numpy==1.26.3\n",
        "!pip install torch==2.1.2\n",
        "!pip install datasets==2.16.1\n",
        "!pip install transformers==4.37.0\n",
        "!pip install wandb==0.16.2\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install trl==0.7.10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "import wandb\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "VU_EbAjVoeq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=2003):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "COemx990prmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_DPO_loss(model_preferred_logprob, model_dispreferred_logprob,\n",
        "                       ref_preferred_logprob, ref_dispreferred_logprob,\n",
        "                       beta=0.5):\n",
        "\n",
        "    preferred_relative_logprob = model_preferred_logprob - ref_preferred_logprob\n",
        "    dispreferred_relative_logprob = model_dispreferred_logprob - ref_dispreferred_logprob\n",
        "\n",
        "    reward_accuracies = (preferred_relative_logprob > dispreferred_relative_logprob).float().mean()\n",
        "    reward_margins = (preferred_relative_logprob - dispreferred_relative_logprob).mean()\n",
        "\n",
        "    loss = -F.logsigmoid(beta * (preferred_relative_logprob - dispreferred_relative_logprob)).mean()\n",
        "\n",
        "    return loss, preferred_relative_logprob.mean(), dispreferred_relative_logprob.mean(), reward_accuracies, reward_margins"
      ],
      "metadata": {
        "id": "S-lTFsMMpuQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_log_prob(logits, labels, prompt_lengths):\n",
        "    log_probs = F.log_softmax(logits, dim=-1) #take softmax across each distribution over vocab space\n",
        "    token_log_probs = torch.gather(log_probs, -1, labels.unsqueeze(-1)).squeeze(-1) #gets just the logits indexed at these tokens\n",
        "\n",
        "    batch_size, seq_len = labels.shape\n",
        "    response_mask = torch.arange(seq_len, device=labels.device).unsqueeze(0) >= prompt_lengths.unsqueeze(1)\n",
        "    response_mask = response_mask.float()\n",
        "\n",
        "    response_log_probs = (token_log_probs * response_mask).sum(dim=-1)\n",
        "    response_lengths = response_mask.sum(dim=-1).clamp(min=1)\n",
        "    return response_log_probs / response_lengths"
      ],
      "metadata": {
        "id": "asnZdWbyp_mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch, tokenizer, max_length, device):\n",
        "    prompt_encodings = tokenizer(\n",
        "        ['Instruct: ' + item['prompt'] + '\\n' for item in batch],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    chosen_encodings = tokenizer(\n",
        "        ['Output: ' + item['chosen'] for item in batch],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    rejected_encodings = tokenizer(\n",
        "        ['Output: ' + item['rejected'] for item in batch],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    prompt_preferred_ids = torch.cat([\n",
        "        prompt_encodings.input_ids,\n",
        "        chosen_encodings.input_ids\n",
        "    ], dim=-1).to(device)\n",
        "\n",
        "    prompt_dispreferred_ids = torch.cat([\n",
        "        prompt_encodings.input_ids,\n",
        "        rejected_encodings.input_ids\n",
        "    ], dim=-1).to(device)\n",
        "\n",
        "    prompt_preferred_mask = torch.cat([\n",
        "        prompt_encodings.attention_mask,\n",
        "        chosen_encodings.attention_mask\n",
        "    ], dim=-1).to(device)\n",
        "\n",
        "    prompt_dispreferred_mask = torch.cat([\n",
        "        prompt_encodings.attention_mask,\n",
        "        rejected_encodings.attention_mask\n",
        "    ], dim=-1).to(device)\n",
        "\n",
        "    prompt_lengths = prompt_encodings.attention_mask.sum(dim=-1) #length of each prompt (not including padding tokens)\n",
        "\n",
        "    return {\n",
        "        'prompt_preferred_ids': prompt_preferred_ids,\n",
        "        'prompt_dispreferred_ids': prompt_dispreferred_ids,\n",
        "        'prompt_preferred_mask': prompt_preferred_mask,\n",
        "        'prompt_dispreferred_mask': prompt_dispreferred_mask,\n",
        "        'prompt_lengths': prompt_lengths\n",
        "    }"
      ],
      "metadata": {
        "id": "-f0kkd__qXCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, ref_model, tokenizer, optimizer, train_dataloader, epochs=1, beta=0.1):\n",
        "    model.train()\n",
        "    ref_model.eval()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            model_preferred_logits = model(\n",
        "                input_ids=batch['prompt_preferred_ids'],\n",
        "                attention_mask=batch['prompt_preferred_mask']\n",
        "            ).logits #shape (batch_size, sequence_length, vocab_size)\n",
        "\n",
        "            model_preferred_logprob = get_log_prob(\n",
        "                model_preferred_logits,\n",
        "                batch['prompt_preferred_ids'],\n",
        "                batch['prompt_lengths']\n",
        "            )\n",
        "\n",
        "            model_dispreferred_logits = model(\n",
        "                input_ids=batch['prompt_dispreferred_ids'],\n",
        "                attention_mask=batch['prompt_dispreferred_mask']\n",
        "            ).logits\n",
        "\n",
        "            model_dispreferred_logprob = get_log_prob(\n",
        "                model_dispreferred_logits,\n",
        "                batch['prompt_dispreferred_ids'],\n",
        "                batch['prompt_lengths']\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                ref_preferred_logits = ref_model(\n",
        "                    input_ids=batch['prompt_preferred_ids'],\n",
        "                    attention_mask=batch['prompt_preferred_mask']\n",
        "                ).logits\n",
        "\n",
        "                ref_preferred_logprob = get_log_prob(\n",
        "                    ref_preferred_logits,\n",
        "                    batch['prompt_preferred_ids'],\n",
        "                    batch['prompt_lengths']\n",
        "                )\n",
        "\n",
        "                ref_dispreferred_logits = ref_model(\n",
        "                    input_ids=batch['prompt_dispreferred_ids'],\n",
        "                    attention_mask=batch['prompt_dispreferred_mask']\n",
        "                ).logits\n",
        "\n",
        "                ref_dispreferred_logprob = get_log_prob(\n",
        "                    ref_dispreferred_logits,\n",
        "                    batch['prompt_dispreferred_ids'],\n",
        "                    batch['prompt_lengths']\n",
        "                )\n",
        "\n",
        "            loss, preferred_relative_logprob, dispreferred_relative_logprob, reward_accuracies, reward_margins = calculate_DPO_loss(\n",
        "                model_preferred_logprob,\n",
        "                model_dispreferred_logprob,\n",
        "                ref_preferred_logprob,\n",
        "                ref_dispreferred_logprob,\n",
        "                beta=beta\n",
        "            )\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print(loss.item())\n",
        "\n",
        "            wandb.log({\n",
        "                'loss': loss.item(),\n",
        "                'preferred_relative_logprob': preferred_relative_logprob.item(),\n",
        "                'dispreferred_relative_logprob': dispreferred_relative_logprob.item(),\n",
        "                'reward_accuracy': reward_accuracies.item(),\n",
        "                'reward_margin': reward_margins.item()\n",
        "            })"
      ],
      "metadata": {
        "id": "9c00Nhtcqb4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = argparse.Namespace()\n",
        "args.epochs = 10\n",
        "args.beta = 0.10\n",
        "args.batch_size = 8\n",
        "args.max_length = 128\n",
        "args.lr = 1e-6\n",
        "args.seed = 2003\n",
        "args.model_name = \"EleutherAI/pythia-70m\"\n",
        "args.dataset_name = \"jondurbin/truthy-dpo-v0.1\"\n",
        "wandb_project = \"dpo\""
      ],
      "metadata": {
        "id": "v3ZQDVHNqhP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(args.seed)\n",
        "\n",
        "wandb.login()\n",
        "wandb.init(project=wandb_project, config=args)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(args.model_name).to(device)\n",
        "ref_model = AutoModelForCausalLM.from_pretrained(args.model_name).to(device)\n",
        "\n",
        "ref_model.requires_grad_(False)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=args.lr)\n",
        "\n",
        "dataset = load_dataset(args.dataset_name, split=\"train\")\n",
        "collate = partial(collate_fn, tokenizer=tokenizer, max_length=args.max_length, device=device)\n",
        "train_dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, collate_fn=collate)"
      ],
      "metadata": {
        "id": "zStZqTWPqhfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, ref_model, tokenizer, optimizer, train_dataloader, epochs=args.epochs, beta=args.beta)\n",
        "\n",
        "model.save_pretrained(\"model-DPO\")"
      ],
      "metadata": {
        "id": "wwA6pYnHtX70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}