# RL4LLMs
RL for LLMs from scratch

In this repo, we aim to implement existing RL-based fine-tuning methods (think DPO, PPO, etc) from scratch. 
